{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurations gÃ©nÃ©rales\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "df = pd.read_csv(\"datas/train.csv\")\n",
    "\n",
    "# AperÃ§u des premiÃ¨res lignes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les valeurs numÃ©riques\n",
    "def extract_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        value = ''.join([c for c in value if c.isdigit() or c == '.'])\n",
    "        return float(value) if value else None\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la conversion\n",
    "df[\"Mileage\"] = df[\"Mileage\"].apply(extract_numeric)\n",
    "df[\"Engine\"] = df[\"Engine\"].apply(extract_numeric)\n",
    "df[\"Power\"] = df[\"Power\"].apply(extract_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"Mileage\"].isna()].index, inplace=True)\n",
    "# VÃ©rification des valeurs manquantes\n",
    "df.fillna(df.select_dtypes(include=['number']).median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()\n",
    "\n",
    "# Extraire la marque depuis la colonne Name\n",
    "df_cleaned[\"Brand\"] = df_cleaned[\"Name\"].apply(lambda x: x.split(\" \")[0] if isinstance(x, str) else \"Unknown\")\n",
    "\n",
    "# Supprimer les colonnes inutiles\n",
    "df_cleaned = df_cleaned.drop([\"Name\", \"New_Price\", \"Seats\"], axis=1)\n",
    "\n",
    "# Suppression des outliers AVANT d'appliquer la mÃ©diane\n",
    "numerical_cols = df_cleaned.select_dtypes(include=['number']).columns\n",
    "\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_cleaned[col].quantile(0.25)\n",
    "    Q3 = df_cleaned[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_cleaned = df_cleaned[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)]\n",
    "\n",
    "# Appliquer la mÃ©diane des prix pour encoder les catÃ©gories\n",
    "categorical_cols = [\"Fuel_Type\", \"Transmission\", \"Owner_Type\", \"Location\", \"Brand\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    median_price = df_cleaned.groupby(col)[\"Price\"].median()\n",
    "    df_cleaned[col] = df_cleaned[col].map(median_price)\n",
    "\n",
    "# Calculer la matrice de corrÃ©lation\n",
    "correlations = df_cleaned.corr()[\"Price\"].sort_values(ascending=False)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Recharger le dataset nettoyÃ©\n",
    "if 'df_cleaned' in locals():\n",
    "    df = df_cleaned.copy()\n",
    "else:\n",
    "    raise NameError(\"Le dataset nettoyÃ© (`df_cleaned`) n'est pas disponible.\")\n",
    "\n",
    "# DÃ©finir les features (X) et la target (y)\n",
    "X = df.drop(columns=[\"Price\"])\n",
    "y = df[\"Price\"]\n",
    "\n",
    "# SÃ©parer en train/test (80% entraÃ®nement, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Appliquer la normalisation (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialiser les modÃ¨les\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Regression (SVR)\": SVR(kernel=\"rbf\"),\n",
    "    \"Neural Network (MLP)\": MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "# Tester les modÃ¨les SANS normalisation\n",
    "results_no_norm = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results_no_norm[name] = {\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"RÂ² Score\": r2_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Tester les modÃ¨les AVEC normalisation\n",
    "results_norm = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    results_norm[name] = {\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"RÂ² Score\": r2_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Convertir les rÃ©sultats en DataFrame\n",
    "df_results_no_norm = pd.DataFrame(results_no_norm).T\n",
    "df_results_norm = pd.DataFrame(results_norm).T\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(\"ðŸ”´ RÃ©sultats modÃ¨les SANS normalisation:\")\n",
    "print(df_results_no_norm)\n",
    "print(\"\\nðŸŸ¢ RÃ©sultats modÃ¨les AVEC normalisation:\")\n",
    "print(df_results_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# DÃ©finition des hyperparamÃ¨tres Ã  tester\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.8, 1],\n",
    "    \"colsample_bytree\": [0.8, 1]\n",
    "}\n",
    "\n",
    "# Initialiser le modÃ¨le XGBoost\n",
    "model_xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# GridSearchCV avec validation croisÃ©e\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ExÃ©cution du GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramÃ¨tres\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Meilleure performance\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(\"âœ… Meilleurs paramÃ¨tres trouvÃ©s :\")\n",
    "print(best_params)\n",
    "print(\"\\nðŸŽ¯ Meilleur score RÂ² obtenu :\", best_score)\n",
    "\n",
    "# RÃ©-entraÃ®ner XGBoost avec les meilleurs paramÃ¨tres\n",
    "best_model = XGBRegressor(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# PrÃ©dictions finales\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Ã‰valuer la performance\n",
    "results_best = {\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_best),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_best)),\n",
    "    \"RÂ² Score\": r2_score(y_test, y_pred_best)\n",
    "}\n",
    "\n",
    "# Convertir les rÃ©sultats en DataFrame\n",
    "df_results_best = pd.DataFrame([results_best])\n",
    "\n",
    "# Afficher les rÃ©sultats finaux\n",
    "print(\"\\nðŸ”µ Performance de XGBoost aprÃ¨s GridSearch :\")\n",
    "print(df_results_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
